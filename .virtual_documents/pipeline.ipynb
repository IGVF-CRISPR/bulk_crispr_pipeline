#!conda create -n perturbseq_pipeline python=3.8
#activate this env



# !pip uninstall GTFProcessing -y
# !pip install git+https://github.com/LucasSilvaFerreira/GTFProcessing.git
#!pip install gtfparse==1.3.0


#!pip install git+https://github.com/LucasSilvaFerreira/Perturb_Loader.git


# !mamba install -c bioconda nextflow -y
# !mamba install -c bioconda kallisto -y
# pip install --quiet kb-python
#!mamba install -c anaconda openpyxl -y 


# !mamba install -c conda-forge r-base -y 
# #the final r shoudl be 4.2.2 FIX IT

# !Rscript -e 'install.packages("BiocManager", repos = "http://cran.us.r-project.org")'
# !Rscript -e 'BiocManager::install("Rhdf5lib")'
# !Rscript -e 'BiocManager::install("rhdf5")'
# !Rscript -e 'install.packages("doParallel", repos = "http://cran.us.r-project.org")'
# !Rscript -e 'install.packages("devtools", repos = "http://cran.us.r-project.org")'
# !mamba install -c conda-forge r-gert -y 
# !mamba install -c conda-forge r-ragg -y
# !Rscript -e 'install.packages("devtools", repos = "http://cran.us.r-project.org")'
# !mamba install -c conda-forge r-ggplot2
# !Rscript -e 'devtools::install_github("katsevich-lab/sceptre")'



#!mamba install -c bioconda fastqc -y


import pandas as pd

df_features = pd.read_excel('5p27sgRNA_guide_metainfo_modified.xlsx')
#MAKESURE TO ADD | TO GUIDES TARGETING THE SAME REGION AND A NUMBER
# df_features[[ 'sgRNA_sequences', 'sgRNA_name']].to_csv('genome_features.txt', sep='\t', header=None, index=None)


get_ipython().getoutput("pwd")


get_ipython().run_cell_magic("writefile", " /n/scratch3/users/l/lf114/pipeline_perturbseq_like/bin/fq_composition.py", """#!/usr/bin/env python

#Read composition discover
import pandas as pd
import matplotlib.pyplot as plt
import os

def get_reads_fasta(fasta):
    check_guides = f"zcat '{fasta}' | head -n 10000 "
    print (check_guides)
    seqs =  os.system(check_guides) #!$check_guides 
    #print (seqs)
    return [ x for x in seqs if '@' not in x and '+' not in x and 'F'not in x]
    
def compositional_bias_calculation(fasta_df, name, dir_out) :  
    plt.rcParams["figure.figsize"] = (25,2)
    plt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))

    df_calculate_percentages = pd.DataFrame([  [ a for a in s[:]] for s in fasta_df ])
    (pd.concat([ (df_calculate_percentages == nucleotide).sum()  for nucleotide in ['A', 'C', 'T', 'G']], axis=1).T - df_calculate_percentages.shape[0] ).std().plot()
    plt.xlim(0,df_calculate_percentages.shape[1])
    plt.xticks(rotation=90)
    plt.title(f'{name}:: + Compositional Bias \n (sd between the 4 nucleotides) ')
    plt.savefig(f'{dir_out}_composition/{name}_composition.png')
    plt.clf()

    
def plot_compositional_bia(R1,R2, prefix_tag):    
    compositional_bias_calculation(get_reads_fasta(R1), name=f'{prefix_tag}_R1' ,dir_out=prefix_tag)   
    compositional_bias_calculation(get_reads_fasta(R2), name=f'{prefix_tag}_R2', dir_out = prefix_tag )   


read1 = os.argv[1]
read2 = os.argv[2]
prefix_tag = os.argv[3]
plot_compositional_bia(read1,read2,prefix_tag)""")









from re import finditer


import numpy as np
conversion = dict(zip('A C T G'.split(' '),'T G A C'.split(' ')))

def get_guide_number_frequent_sequence(curr_seq):
    curr_seq
    check_guides = get_ipython().getoutput("zcat '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz' | head -n 100000")
    #check_guides = ['CAAGTTGATAACGGACTAGCCTTATTTAAACTTGCTATGCTGTTTCCAGC']
    len_seq = len([i for i in check_guides if curr_seq in i])
    match_mean_pos = np.mean([   [f.span() for f in  finditer(curr_seq, i )][0] for i in check_guides if curr_seq in i])

    print (len_seq, match_mean_pos)
    return  len_seq, match_mean_pos

get_guide_number_frequent_sequence('CAAGTTGATAACGGACTAGCCTTATTTAAACTTGCTATGCTGTTTCCAGC')


df_features
import numpy as np
conversion = dict(zip('A C T G'.split(' '),'T G A C'.split(' ')))
from re import finditer

def get_guide_number(curr_seq):
    curr_seq = ''.join( [conversion[s] for s in curr_seq[::-1]])
    check_guides = get_ipython().getoutput("zcat '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz' | head -n 100000")
    len_seq = len([i for i in check_guides if curr_seq in i])
    match_mean_pos = np.mean([   [f.span() for f in  finditer(curr_seq, i )][0] for i in check_guides if curr_seq in i])

    print (len_seq, match_mean_pos)
    return  len_seq, match_mean_pos





    

df_features['guide_reads_in_fastq_samples'] = df_features['sgRNA_sequences'].apply(lambda x : get_guide_number(x)[0]  )
#f_features['guide_mean_position_R2'] = df_features['sgRNA_sequences'].apply(lambda x : get_guide_number(x)[1]  )


df_features.index = df_features['sgRNA_ID']
df_features['guide_reads_in_fastq_samples'].plot.bar()


get_ipython().getoutput("mkdir fqqc_quality_R1")
get_ipython().getoutput("fastqc -o fqqc_quality_R1 /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R1_001.fastq.gz -t 8 ")



get_ipython().getoutput("mkdir fqqc_quality_R2")
get_ipython().getoutput("fastqc -o fqqc_quality_R2 /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz -t 8 ")




len('ATCACCCTTACTTGCATCAGCAAAGGGGTCGAAAGAGTGGAGGTTCTGGATAGCGGACATACGATACGATTCCTTTTCCTCGGTGGAAACGGCCTGCGGAA')


10xv3     
0,0,16:0,16,26:0,26,0,1,0,0    -> sc5'pe
#params.CHEMISTRY = '0,0,16:0,16,26:0,26,0,1,0,0'



#testing different lanes
# params.FASTQ_FILES_TRANSCRIPTS = ['/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz',
#                                   '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz',
#                                  '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz']

# params.FASTQ_NAMES_TRANSCRIPTS = ['S1_L1',
#                                   'S1_L2',
#                                   'S2_L1']


# params.FASTQ_FILES_GUIDES = ['/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz',
#                             '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz' ]

# params.FASTQ_NAMES_GUIDES = ['S1_L1' ,
#                              'S1_L2']





// Declare syntax version
nextflow.enable.dsl=2
// Script parameters
params.GTF_GZ_LINK = 'http://ftp.ensembl.org/pub/release-106/gtf/homo_sapiens/Homo_sapiens.GRCh38.106.gtf.gz'
params.TRANSCRIPTOME_REFERENCE = "human"
params.KALLISTO_BIN = '/home/lf114/miniconda3/envs/perturbseq_pipeline/bin/kallisto'
params.GENOME = 'https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz'
params.GUIDE_FEATURES = '/n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/5p27sgRNA_guide_metainfo_modified.xlsx'
params.CHEMISTRY = '0,0,16:0,16,26:0,26,0,1,0,0'
params.THREADS = 15
params.DISTANCE_NEIGHBORS = 1000000
params.IN_TRANS = "FALSE"

params.FASTQ_FILES_TRANSCRIPTS = ['/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz']

params.FASTQ_NAMES_TRANSCRIPTS = ['S1_L1']


params.FASTQ_FILES_GUIDES = ['/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAsgRNA_02KRWK_11408_S15_L001_R2_001.fastq.gz' ]

params.FASTQ_NAMES_GUIDES = ['S1_L1']




params.CREATE_REF = false

workflow {
   gtf_out = downloadGTF(params.GTF_GZ_LINK)
   downloadReference(Channel.of(params.TRANSCRIPTOME_REFERENCE), Channel.of(params.KALLISTO_BIN) )
   downloadGenome (Channel.of(params.GENOME))
   guide_feature_preprocessed = guidePreprocessing(params.GUIDE_FEATURES)
   creatingGuideRef( downloadGenome.out.genome, Channel.of(params.KALLISTO_BIN), guide_feature_preprocessed.guide_features, params.CREATE_REF )
    
    
   map_rna = mappingscRNA (
                 Channel.from(params.FASTQ_NAMES_TRANSCRIPTS),
                 Channel.from(params.FASTQ_FILES_TRANSCRIPTS),
                 downloadReference.out.transcriptome_idx.collect(),
                 downloadReference.out.t2t_transcriptome_index.collect(),
                 Channel.of(params.KALLISTO_BIN).collect(),
                 Channel.of(params.CHEMISTRY).collect(),
                 Channel.of(params.THREADS).collect(),

                )
    
   map_guide = mappingGuide (
                 Channel.from(params.FASTQ_NAMES_GUIDES),
                 Channel.from(params.FASTQ_FILES_GUIDES), 
                 creatingGuideRef.out.guide_index.collect(),
                 creatingGuideRef.out.t2tguide_index.collect(),
                 Channel.of(params.KALLISTO_BIN).collect(),
                 Channel.of(params.CHEMISTRY).collect(),
                 Channel.of(params.THREADS).collect())
    
    
    dir_count_files = map_guide.ks_guide_out.join(map_rna.ks_transcripts_out, remainder: true).flatten().toList().view()
    dir_count_files.view()
    df_initialized = preprocessing(dir_count_files)
    out_processed = filtering(df_initialized.df_initial_files, dir_count_files )
    out_processed.guide_ann.view()
    out_processed.transcripts_ann.view()
    pert_loader_out = PerturbLoaderGeneration(out_processed.guide_ann, out_processed.transcripts_ann , gtf_out.gtf , params.DISTANCE_NEIGHBORS, params.IN_TRANS )
    runSceptre(pert_loader_out.perturb_piclke)
    
    
}


process downloadGTF {
    input:
    val gtf_gz_path
    output:
    path "transcripts.gtf" , emit: gtf
    script:
    """    
    wget -O - $gtf_gz_path | gunzip -c > transcripts.gtf
    """
}



process downloadReference {
    input:
    val ref_name 
    path k_bin 
    
    output:
    path "transcriptome_index.idx" , emit: transcriptome_idx
    path "transcriptome_t2g.txt"   , emit: t2t_transcriptome_index

    script:
    """
        kb ref -d $ref_name -i transcriptome_index.idx -g transcriptome_t2g.txt --kallisto ${k_bin}
    """
}

process downloadGenome {
    input:
    val genome_path
    output:
    path "genome.fa.gz" , emit: genome
    script:
    """
        wget $genome_path -O genome.fa.gz 
    """


}


process guidePreprocessing {
    cache 'lenient'
    debug true
    input:
    path (guide_input_table)
    output:
    path "guide_features.txt" , emit: guide_features
    script:
    """    
    python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/guide_table_processing.py  $guide_input_table
    """
}





process creatingGuideRef {
    cache 'lenient'
    input:
    val genome_path
    path k_bin
    path guide_features
    val create_ref
    output:
    path "guide_index.idx" ,  emit: guide_index
    path "t2guide.txt" , emit: t2tguide_index
    script:
    
    """
        kb ref -i guide_index.idx -f1 $genome_path -g t2guide.txt --kallisto $k_bin  --workflow kite $guide_features 

    """


    
}

process mappingscRNA {
    debug true
    input:
    tuple val(out_name_dir)
    tuple val(string_fastqz)
    tuple path(transcriptome_idx)
    tuple path(t2t_transcriptome_index)
    tuple path(k_bin)
    tuple val(chemistry)
    tuple val(threads)
    output:
    path ("${out_name_dir}_ks_transcripts_out"),  emit: ks_transcripts_out

    script:
    
        """
        kb count -i $transcriptome_idx -g  $t2t_transcriptome_index --verbose --workflow kite --h5ad --kallisto $k_bin -x $chemistry -o ${out_name_dir}_ks_transcripts_out -t $threads $string_fastqz  --overwrite                                                                   
        """
} 

process mappingGuide {
    debug true
    input:
    tuple val(out_name_dir)
    tuple val(string_fastqz)
    tuple (path guide_index)
    tuple (path t2tguide_index)
    tuple path(k_bin)
    tuple val(chemistry)
    tuple val(threads)
    output:
    path ("${out_name_dir}_ks_guide_out"),  emit: ks_guide_out
    script:
        """
        kb count -i $guide_index  -g  $t2tguide_index --verbose   --report  --workflow kite --h5ad --kallisto $k_bin -x 0,0,16:0,16,26:0,26,0,1,60,86 -o ${out_name_dir}_ks_guide_out -t $threads $string_fastqz --overwrite
        """
} 

 


process capture_variables_and_save_list{
    debug true
    input:
    val received
    val out_name
    output:
    path "${out_name}.txt",  emit: out_file
    script:
    """
    echo  '${received}' > ${out_name}.txt 
    """
}








process preprocessing {
    debug true
    input:
    path (count_list)
    output:
    path 'initial_preprocessing_file_names.txt', emit: df_initial_files
    script:
    """    
    python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/preprocessing.py  ${count_list} 

    """   
    
}


process filtering{
    debug true
    input:
    path (path_df)
    path (all_files)
    output:
    path 'results_per_lane/processed_anndata_guides_data.h5ad', emit: guide_ann
    path 'results_per_lane/processed_anndata_transcripts_data.h5ad',  emit: transcripts_ann
    script:
    """
    #use -merge to merge the guides
    # I need to add these parameters to the pipeline config  mito...cellnumber...merge...guide_limit
    python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/filtering_and_lane_merging.py --path ${path_df} --expected_cell_number 8000 --mito_specie hsapiens --mito_expected_percentage 0.2 --percentage_of_cells_to_include_transcript 0.2  --guide_umi_limit 5

    """
}



IN_GUIDE = args.in_guide
IN_EXP = args.in_exp
GTF_IN = args.gtf_in
IN_TRANS = args.in_trans
DISTANCE_FROM_GUIDE = args.distance_from_guide

process PerturbLoaderGeneration {
    debug true
    input:
    path (in_guide)
    path (in_exp)
    path (gtf_in)
    val (distance_from_guide)
    val (in_trans)
    output:
    path 'perturbdata.pkl', emit: perturb_piclke
    
   """ 
   python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/PerturbLoader_generation.py --in_guide $in_guide --in_exp $in_exp --gtf_in $gtf_in  --distance_from_guide $distance_from_guide --in_trans $in_trans

    """   
}


process runSceptre {
    debug true
    input:
    path (perturbloader_pickle)

    
   """ 
   python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/runSceptre.py $perturbloader_pickle

    """   
}








get_ipython().run_cell_magic("writefile", " guide_table_processing.py", """import pandas as pd
import sys

print ('Guides targeting the same element should have the same element name ex: ATP2B4, ATP2B4, ATP2B4. The pipeline will automatically detect them as the same element')
#df_features = pd.read_excel('5p27sgRNA_guide_metainfo_modified.xlsx')
df_features = pd.read_excel(sys.argv[1])
reconstruct_df = []
for k, v in df_features.groupby('Target_name'):
    v_x = v.copy()
    v_x['Target_name'] = [ f'{k}|{n+1}'  for n in range (v_x.shape[0])]
    v_x['pipeline_id'] = v_x.apply(lambda x : f"{x['Target_name']}_sgrna_{x['chr']}:{x['start']}:{x['end']}" ,axis=1)

    reconstruct_df.append(v_x)
df_features_names_changed = pd.concat(reconstruct_df)
df_features_names_changed[[ 'sgRNA_sequences', 'pipeline_id']].to_csv('guide_features.txt', sep='\t', header=None, index=None)

""")


get_ipython().run_cell_magic("writefile", " preprocessing.py", """import pandas as pd
import sys

def preparing_files_initialing(path_list):
    
    print ('preparing files...')
    # create_main_fig_dir = 'results_per_lane'
    # create_case_doesnt_exist(create_main_fig_dir)
    # #capturing files generated (guides and ScRNAseq)
    # #how to capture the file names?
    # assert len(set([f.parent.parent.name for f in path_objects_test])) == len(path_objects_test), 'This seems like multiple runs inside the same directory, use resume to avoid it or change the directory'
    dir_fastqz = [f + '/counts_unfiltered/adata.h5ad' for f in path_list]
    df_files = pd.DataFrame(dir_fastqz, columns=['file_path'])
    df_files['sample'] = df_files['file_path'].apply(lambda x : 'Guide' if 'guide' in x else 'scRNA' )
    df_files['lane'] =   df_files['file_path'].apply(lambda x : x.split('/')[-3].split('_')[1].replace('L', '') )  # check if how it will be handled in the future
    
    print (len(dir_fastqz))
    print (df_files.shape)
    print (df_files)
    df_files.to_csv('initial_preprocessing_file_names.txt', sep='\t', index=None)
    #return df_files

    


path_in_files = sys.argv[1:]
print (sys.argv)
preparing_files_initialing(path_in_files)
""")


get_ipython().run_cell_magic("writefile", " PerturbLoader_generation.py", """
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import anndata
import pandas as pd
from GTFProcessing import GTFProcessing
from tqdm import tqdm
import pickle
import sys


import argparse

parser = argparse.ArgumentParser(description='Description of your script')

parser.add_argument('-g', '--in_guide', type=str, required=True, help='Description of the first argument')
parser.add_argument('-e', '--in_exp', type=str, required=True, help='Description of the second argument')
parser.add_argument('-f', '--gtf_in', type=str, required=True, help='Description of the third argument')
parser.add_argument('-t', '--in_trans', type=str, required=True, default="FALSE", help='Description of the fourth argument (default: FALSE)')
parser.add_argument('-d', '--distance_from_guide', type=int, default=1000000, help='Description of the fifth argument (default: 1000000)')

args = parser.parse_args()

IN_GUIDE = args.in_guide
IN_EXP = args.in_exp
GTF_IN = args.gtf_in

IN_TRANS = False if args.in_trans.upper() == 'FALSE' else True

print (f'is in trans? =  {IN_TRANS} given parameter {args.in_trans } ')
DISTANCE_FROM_GUIDE = int(args.distance_from_guide)



NUMBER_FOR_RANDOM_CONTROLS = 10




# IN_GUIDE = '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_4/ff/847841e216c2cd64fba0e44c53af2c/results_per_lane/processed_anndata_guides_data.h5ad'
# IN_EXP =   '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_4/4b/9c2870f9776840fc09e8de5384ce40/results_per_lane/processed_anndata_transcripts_data.h5ad' 
# GTF_IN =   '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_4/cd/d25097d237358a3a48282ece7811da/transcripts.gtf'
# DISTANCE_FROM_GUIDE = 1000000
# NUMBER_FOR_RANDOM_CONTROLS = 10





ann_exp =   anndata.read(IN_EXP)
ann_guide = anndata.read(IN_GUIDE)

print (ann_guide.var.index.values)

df_element_guide = pd.DataFrame([[x.split('|')[0] for x in ann_guide.var.index.values], [x.split('|')[0] for x in ann_guide.var.index.values]]).T
df_element_guide = df_element_guide.drop_duplicates()
df_element_guide.columns = ['Element', 1]
df_element_guide = df_element_guide.set_index('Element')
df_element_guide.values.tolist()

del df_element_guide[1]

def check_guide(guide_group, guide_name):
  if guide_name.split('|')[0]  ==  guide_group:
    return 1
  else:
    return 0

df_to_elements = pd.DataFrame([ [check_guide (guide_group,guide_name ) for guide_name in   ann_guide.var.index.values ]      for guide_group in df_element_guide.index    ])

df_to_elements.index = df_element_guide.index

df_to_elements.columns = ann_guide.var.index.values
# df_to_elements.index.values.tolist()

# df_to_elements

ann_Element_guide =  anndata.AnnData(X=df_to_elements)
#ann_Element_guide.var
dict_capure_guide_coords = {k.split('|')[0] : k.split('_')[-1] for k in df_to_elements.columns}



gtf = GTFProcessing(GTF_IN)
df_gtf_refseq = gtf.get_gtf_df()


df_gtf_refseq_gene =df_gtf_refseq[ df_gtf_refseq['feature'] == 'gene']
set_gene_on_annexp = set(ann_exp.var.index.values)
df_gtf_refseq_gene = df_gtf_refseq_gene[df_gtf_refseq_gene['gene_name'].apply(lambda x : x in set_gene_on_annexp)]

df_gtf_refseq_gene['gene_real_start'] = df_gtf_refseq_gene.apply(lambda x : x['start'] if x['strand'] == "+" else x['end'], axis=1 )


def capture_genes(gene_query,   DISTANCE = 1000000, number_for_random_genes=10, in_trans=False):
  # case coord use a list
#   if 'pos_control_' in gene_query:
#     return set()
#   if 'random' in  gene_query:
#     return set(df_gtf_refseq_gene.sample(number_for_random_genes)['gene_name'].values.tolist())

#   if 'scrambled' in  gene_query:
#     return set(df_gtf_refseq_gene.sample(number_for_random_genes)['gene_name'].values.tolist())
  if in_trans:
    return set(df_gtf_refseq_gene['gene_name'].values.tolist())

  # coord_bool=False
  # if ':' in gene_query:
    #print (gene_query, 'gquery')
    #print (gene_query.split(':')[0].replace('chr', ''))
  coord_bool=True



  #   if 'scrambled' in  gene_query:
#     return set(df_gtf_refseq_gene.sample(number_for_random_genes)['gene_name'].values.tolist())
  if coord_bool:
      gene_query_use = dict_capure_guide_coords[gene_query]
      print (gene_query_use, len(gene_query_use))
      if ':' in gene_query_use:
        chr =  gene_query_use.split(':')[0].replace('chr', '')
        coord =  int(gene_query_use.split(':')[1].split(':')[0])
        
      else:
        chr,  coord = gene_query
      #print (chr, coord)

  # else:
  if len(df_gtf_refseq_gene.query(f'gene_name == "{gene_query}" ')) == 0:
    print (gene_query,'len == 0')
    return set(df_gtf_refseq_gene.sample(number_for_random_genes)['gene_name'].values.tolist())

  
  chr,  coord = df_gtf_refseq_gene.query(f'gene_name == "{gene_query}" ')[['chr', 'gene_real_start']].iloc[0].values.tolist()

  #print (df_gtf_refseq_gene.query(f'chr == "{chr}"  '))
  #should accet raw coordinates as well (to capture enhancer)
  return set(df_gtf_refseq_gene.query(f'chr == "{chr}"  ')[np.abs(df_gtf_refseq_gene.query(f'chr == "{chr}"  ')['gene_real_start'] - coord)< DISTANCE]['gene_name'].values)





def is_gene_included(gene):
  
  if '_TSS' in gene:
    gene = gene.replace('_TSS', '')
  print (gene)
  gene_set = capture_genes(gene, DISTANCE = int(DISTANCE_FROM_GUIDE),
                           number_for_random_genes = NUMBER_FOR_RANDOM_CONTROLS,
                           in_trans=IN_TRANS)
  #print(gene, len(gene_set))
  return gene_set



final_element_binary = []
for element in  tqdm(ann_Element_guide.obs.index):
  print (element)    
  set_of_elements = is_gene_included(element)
  print (set_of_elements, 'set_of_elements')
  presence_gene_e = []
  for e in  ann_exp.var.index.values:
    #print (e)
    if e in set_of_elements:
      presence_gene_e.append(1)
    else:
      presence_gene_e.append(0)
  final_element_binary.append(presence_gene_e)




Elements_x_tested_genes =    pd.DataFrame(final_element_binary, columns = ann_exp.var.index.values, index=ann_Element_guide.obs.index)
ann_Element_x_tested_genes=  anndata.AnnData(X=Elements_x_tested_genes)


def add_test_type(e):
  if '_TSS' in e:
    return 'POSITIVE_CONTROL'
  if 'random' in e or 'scrambled' in e:
    return 'NEGATIVE_CONTROL'
  if 'chr' in e:
    return 'PUTATIVE_ENHANCER'


ann_Element_x_tested_genes.obs['GUIDE_TYPE'] = [add_test_type(e) for e in Elements_x_tested_genes.index.values]

from Perturb_Loader import PERTURB_MANIPULATE
p = PERTURB_MANIPULATE(ann_exp, ann_guide, ann_Element_guide, ann_Element_x_tested_genes)
filename = 'perturbdata.pkl'
outfile = open(filename,'wb')
pickle.dump(p,outfile)
outfile.close()




""")





get_ipython().run_cell_magic("writefile", " runSceptre.py", """import pandas as pd
import numpy as np
from tqdm import tqdm
import pickle
import os
import sys


#loading picke file
PICKE_PATH = 'perturbdata.pkl'
#PICKE_PATH = sys.argv[1]

with open(PICKE_PATH, 'rb') as f:
    p = pickle.load(f)




def run_sceprte_by_element(ELEMENT, name_element='positive_control'):
  path_element = f'{ELEMENT}'
  os.system(f'mkdir {path_element}')
  p.genes_to_test_count(ELEMENT) # Genes on a 1MB region  
  p.genes_to_test_count(ELEMENT).T.to_csv(f'{path_element}/gene_exp_one_gene_guide.txt', sep=',')
  df_guides_sceptre = pd.DataFrame([   p.capture_guide(x) for x in p.capture_element_guides(ELEMENT) ])
  df_guides_sceptre.columns  = p.genes_to_test_count(ELEMENT).T.columns.values.tolist()
  df_guides_sceptre.index = p.capture_element_guides(ELEMENT)
  print ('Guide number:', df_guides_sceptre.sum())
  print ('Guide number:', df_guides_sceptre.sum(1))
  dict_guides_to_analyze_in_the_limit = set(df_guides_sceptre.sum(1)[df_guides_sceptre.sum(1) > 30].index.values)
  print('higher than  > guides 30 ', dict_guides_to_analyze_in_the_limit )


  df_guides_sceptre.to_csv(f'{path_element}/guides_one_gene_guide.txt', sep=',')
  df_cov_mod = p.capture_covariates().copy()  # to filter for single factors (case not batch)
  print ('set', set(df_cov_mod['bath_number'].values), len(set(df_cov_mod['bath_number'].values)) == 1 )
  if len(set(df_cov_mod['bath_number'].values)) == 1:
    del df_cov_mod['bath_number']
  df_cov_mod.to_csv(f'{path_element}/covariates.txt', sep=',')


  df_pairs = pd.DataFrame(np.array([ [ [g,e,name_element] for g in p.genes_to_test_count(ELEMENT).columns ] for e in p.capture_element_guides(ELEMENT)   if e in dict_guides_to_analyze_in_the_limit ]  ).reshape(-1,3)     )
  df_pairs.columns  =  'gene_id gRNA_group pair_type'.split(' ')
  df_pairs.to_csv(f'{path_element}/pairs.txt', sep=',', index=False)




  r=f'''
      setwd("{path_element}")
      print(getwd())
      library(sceptre)
      library(tibble)
      library(dplyr)
      exp =  as.matrix(read.table( 'gene_exp_one_gene_guide.txt' , sep=',' ,header=TRUE, row.names=1, check.names=FALSE) )
      #print( tail(colnames(exp), 30) )
      #print( tail(row.names(exp), 30) )

      g_I = as.matrix( read.table('guides_one_gene_guide.txt',     sep=',' , header=TRUE, row.names=1 , check.names=FALSE))
      #g_I[,] = g_I == 1
      #print( tail(colnames(g_I), 30) )
      #print( tail(row.names(g_I), 30) )



      cov = read.table('covariates.txt',                sep=',', header=TRUE, row.names=1)
      if ('bath_number' %in% names(cov) ) {{
        cov$bath_number =  as.factor(cov$bath_number)
      }}



      #print(tail( row.names(cov)  , 30))
      pairs_test = read.table('pairs.txt',              sep=',', header=TRUE , check.names=FALSE)
      pairs_test = as_tibble(pairs_test)
      pairs_test$pair_type = as.factor(pairs_test$pair_type)


      result <- run_sceptre_high_moi(gene_matrix = exp, 
                                            combined_perturbation_matrix = g_I, 
                                            covariate_matrix = cov,
                                            gene_gRNA_group_pairs = pairs_test,

                                            side='left',
                                            )


      result$p_value
      result$z_value

      write.table(result ,"results.txt" )

      '''

  file_save = open('r_script.r', 'w')
  file_save.write(r)
  file_save.close()
  os.system('Rscript r_script.r')



#p.extract_element_per_type('PUTATIVE_ENHANCER')
elements_sceptre = p.show_elements()
for elements in tqdm(elements_sceptre):
  print ('-'*20, elements, '-'*20)
  print ('Element')
  if not os.path.exists(f'{elements}'):
    print ('-'*20, 'run', elements , '-'*20)
    run_sceprte_by_element(elements,
                           name_element='all_elements_test')
  
  else:
      print ('-'*20, 'not run ', elements, '-'*20)

    
    
    """)


#df_features_names_changed


# !nextflow log


get_ipython().getoutput("pwd")


get_ipython().getoutput("cd /n/scratch3/users/l/lf114/guillaume_perturb_data; nextflow run /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/perturb_pipeline.nf  -with-timeline /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/timelile_2.html -w  testing_w_option_12")



get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_9_SINGLE_sample_incis | grep 'results.txt'")


get_ipython().getoutput("cat /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/a1/fdbf5d2659b569ed23de82ffcf3792/BCL11A/pairs.txt")


get_ipython().run_cell_magic("writefile", "  /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_9_SINGLE_sample_incis/e1/ed7dfa053334f661626f81ea482217/r_script.r", """
setwd("BCL11A")
  print(getwd())
  library(sceptre)
  library(tibble)
  library(dplyr)
  exp =  as.matrix(read.table( 'gene_exp_one_gene_guide.txt' , sep=',' ,header=TRUE, row.names=1, check.names=FALSE) )
  #print( colnames(exp))
  #print(row.names(exp) )

  g_I = as.matrix( read.table('guides_one_gene_guide.txt',     sep=',' , header=TRUE, row.names=1 , check.names=FALSE))
  print (rownames(g_I))
    
  print(rowSums(g_I))
  
#   #print( colnames(g_I) )
  #print( row.names(g_I) )



  cov = read.table('covariates.txt',                sep=',', header=TRUE, row.names=1)
  if ('bath_number' %in% names(cov)){
    cov$bath_number =  as.factor(cov$bath_number)
  }


  #print(tail( row.names(cov)  , 30))
  pairs_test = read.table('pairs.txt',              sep=',', header=TRUE , check.names=FALSE)
  pairs_test = as_tibble(pairs_test)
  pairs_test$pair_type = as.factor(pairs_test$pair_type)


  result <- run_sceptre_high_moi(gene_matrix = exp, 
                                        combined_perturbation_matrix = g_I, 
                                        covariate_matrix = cov,
                                        gene_gRNA_group_pairs = pairs_test,
                                      
                                        side='left',
                                        parallel=TRUE)


  result$p_value
  result$z_value

  write.table(result ,"results.txt" )
  """)


get_ipython().getoutput("cd /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_9_SINGLE_sample_incis/e1/ed7dfa053334f661626f81ea482217/ ;Rscript r_script.r")






get_ipython().run_cell_magic("writefile", " /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_8_SINGLE_sample_incis/56/190aa9aa2a6ef021613b188ccddae9/r_script.r", """
setwd("BCL11A")
  print(getwd())
  library(sceptre)
  library(tibble)
  library(dplyr)
  exp =  as.matrix(read.table( 'gene_exp_one_gene_guide.txt' , sep=',' ,header=TRUE, row.names=1, check.names=FALSE) )
  #print( colnames(exp))
  #print(row.names(exp) )

  g_I = as.matrix( read.table('guides_one_gene_guide.txt',     sep=',' , header=TRUE, row.names=1 , check.names=FALSE))
  print (rownames(g_I))
    #g_I= g_I[,30] == 1
  #print( colnames(g_I) )
  print( row.names(g_I) )



  cov = read.table('covariates.txt',                sep=',', header=TRUE, row.names=1)
  cov$bath_number =  as.factor(cov$bath_number)



  #print(tail( row.names(cov)  , 30))
  pairs_test = read.table('pairs.txt',              sep=',', header=TRUE , check.names=FALSE)
  pairs_test = as_tibble(pairs_test)
  pairs_test$pair_type = as.factor(pairs_test$pair_type)


  result <- run_sceptre_high_moi(gene_matrix = exp, 
                                        combined_perturbation_matrix = g_I, 
                                        covariate_matrix = cov,
                                        gene_gRNA_group_pairs = pairs_test,
                                      
                                        side='left',
                                        )


  result$p_value
  result$z_value

  write.table(result ,"results.txt" )
  """)





pd.read_csv('/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/63/c0f78aaab94fc421775ba900c78137/BCL11A/guides_one_gene_guide.txt').sum(1)



get_ipython().getoutput("cp /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/a1/fdbf5d2659b569ed23de82ffcf3792/r_script.r  /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/a1/fdbf5d2659b569ed23de82ffcf3792/BCL11A	")
get_ipython().getoutput("cd /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/a1/fdbf5d2659b569ed23de82ffcf3792/BCL11A;Rscript  r_script.r")





pd.read_csv('/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/a1/fdbf5d2659b569ed23de82ffcf3792/gene_exp_one_gene_guide.txt')  


get_ipython().getoutput("ls /n/scratch3/users/l/lf114/guillaume_perturb_data/results/S1_L1_ks_guide_out/S1_L1_ks_guide_out/counts_unfiltered/adata.h5ad")


get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe | grep guides")


get_ipython().getoutput("cat /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe/61/5dbda2e67d020ae3967d7e3a7030a4/r_script.r")


get_ipython().getoutput("cat /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe/61/5dbda2e67d020ae3967d7e3a7030a4/DNMT1/guides_one_gene_guide.txt")


get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe | grep results.txt | xargs cat")




get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_4/ | grep json | xargs head")



get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/ | grep r_script ")


get_ipython().getoutput("Rscript /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/c6/c0a1de5a104e7a9a36705a415f3c51/r_script.r")




get_ipython().getoutput("cat /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/c6/c0a1de5a104e7a9a36705a415f3c51/r_script.r")


get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/ |grep   gene_exp_one_gene_guide")


import pandas as pd
pd.read_csv( '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/c6/c0a1de5a104e7a9a36705a415f3c51/DNMT1/covariates.txt')
# df_sub = pd.read_csv( '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/c6/c0a1de5a104e7a9a36705a415f3c51/DNMT1/covariates.txt')
# del df_sub['bath_number']
# df_sub.to_csv('/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_6_SINGLE_sample_incis/c6/c0a1de5a104e7a9a36705a415f3c51/DNMT1/covariates.txt', index=None)


pd.read_csv( '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe/61/5dbda2e67d020ae3967d7e3a7030a4/DNMT1/covariates.txt')


pd.read_csv( '/n/scratch3/users/l/lf114/guillaume_perturb_data/testing_w_option_5_pe/61/5dbda2e67d020ae3967d7e3a7030a4/DNMT1/gene_exp_one_gene_guide.txt').head()


p.show_guides()


p.capture_gene_count('PIEZO1')


p.captu('PIEZO1')


p.show_elements()





# #!head -n 1000 $GTF_IN  >  micro_gtf.gtf

# %load_ext autoreload


# from GTFProcessing import GTFProcessing



# gtf = GTFProcessing('micro_gtf.gtf')





#!mamba upgrade r r-base

























get_ipython().getoutput("Rscript -e 'library(sceptre)'")














get_ipython().getoutput("find /n/scratch3/users/l/lf114/guillaume_perturb_data/ | results")





['S3', 'L1', '5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz', '5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz'],
['S3', 'L2', '5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz', '5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz']


#!kb ref -i guide_index.idx -f1 hg38.fa.gz -g t2guide.txt --kallisto ~/miniconda3/bin/kallisto --overwrite --workflow kite gasperini_pilot_guide_sequences.tsv 




# process downloadReference {
#   input:
#     path query
#     path db
#   output:
#     path "top_hits.txt"

#     """
#     blastp -db $db -query $query -outfmt 6 > blast_result
#     cat blast_result | head -n 10 | cut -f 2 > top_hits.txt
#     """
# }

# process extractTopHits {
#   input:
#     path top_hits

#   output:
#     path "sequences.txt"

#     """
#     blastdbcmd -db $db -entry_batch $top_hits > sequences.txt
#     """
# }


# Downloading human and mouse references

get_ipython().getoutput("kb ref ")



get_ipython().run_line_magic("%writefile", " test.nf")

nextflow.enable.dsl=2

params.a_list = ['a', 'b', 'c', 'd']
params.n_list = ['1', '2', '3', '4']
params.n_single = ['single']


params.FASTQ_FILES_TRANSCRIPTS = ['/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz',
                                  '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz',
                                '/n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R1_001.fastq.gz /n/scratch3/users/l/lf114/guillaume_perturb_data/5p27sgRNAGex_02KRWD_11408_S3_L001_R2_001.fastq.gz']

params.FASTQ_NAMES_TRANSCRIPTS = ['S1_L1',
                                  'S1_L2',
                                  'S2_L1']


params.SECOND_FASTQ_NAMES_TRANSCRIPTS = ['2_S1_L1',
                                  '2_S1_L2',
                                  '2_S2_L1']



params.TEST_OUT_NAME = 'my_test_out_name'
params.SEC_TEST_OUT_NAME = 'SEC_my_test_out_name'


process test {
        debug true
        input:
        tuple val(a) 
        tuple val(n)
        val single_value
        output:
        tuple ( file("${n}.txt"), file("${n}.test") )
        

        script:
     """
     echo $single_value
     echo $a > ${n}.txt
     echo $n > ${n}.test

     """
    
    
}


process testing_pipe {
    debug true
    input:
    tuple val(a_in), val(b_in)
    output:
    tuple (file("${a_in}.final")), emit: my_pipe_result
    script:
     """
     cat ${a_in} > ${a_in}.final  
     """
}

process capture_variables_and_save_list{
    debug true
    input:
    val received
    val out_name
    output:
    tuple path("${out_name}_b.txt"), path("${out_name}_a.txt") ,  path("${out_name}_c.txt") 
    script:
    """
    echo  '${received}' > ${out_name}_a.txt
    echo  '${received}' > ${out_name}_b.txt 
    echo  '${received}' > ${out_name}_c.txt 
    """
}


process capture_variables_and_save_list_2{
    debug true
    input:
    val received
    val out_name
    output:
    tuple path("${out_name}_b.txt"), path("${out_name}_a.txt") 
    script:
    """
    echo  '${received}' > ${out_name}_a.txt
    echo  '${received}' > ${out_name}_b.txt 
    """
}

process open_capture{
    debug true
    input:
    path (file_name) 
    script:
    """
    echo 'this is cat...'
    echo   '${file_name}' 
    python /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/test_multiple_files.py ${file_name}
    """
    
}




workflow {

              
    f_names_1 = capture_variables_and_save_list  (Channel.value(params.FASTQ_NAMES_TRANSCRIPTS), params.TEST_OUT_NAME)
    f_names_2 = capture_variables_and_save_list_2(Channel.value(params.SECOND_FASTQ_NAMES_TRANSCRIPTS), params.SEC_TEST_OUT_NAME)

    dir_files = f_names_1.merge(f_names_2).flatten().toList()
    dir_files.view()
    open_capture(dir_files)

                
}





get_ipython().getoutput("nextflow run test.nf -with-report /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/test.html -w teste_02")



get_ipython().run_cell_magic("writefile", " test_multiple_files.py", """import sys
import pandas as pd



print('MY SYS PYTHON:  ',sys.argv)

for p in sys.argv[1:]:
    print (pd.read_csv(p, header=None, sep='\t'))
""")


   result = test(Channel.from(params.FASTQ_FILES_TRANSCRIPTS),
                 Channel.from(params.FASTQ_NAMES_TRANSCRIPTS),  Channel.from(params.n_single).collect()) 


#!rm -r /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/results/


get_ipython().getoutput("ls /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/work/dc/308af235dcc7e8a3e6b75184c4a286/S1_L2.txt")


publishDir "results/${n}", mode: 'copy'
publishDir "results/${n}", mode: 'copy'


  
   testing_pipe(result)


import pandas as pd





check_comand_error = get_ipython().getoutput("ls -lt teste_02 ")
last_dir = check_comand_error[1].split(' ')[-1]
dir_cat = get_ipython().getoutput("ls teste_02/$last_dir")
dir_cat_in = dir_cat[0]
get_ipython().getoutput("cat teste_02/$last_dir/$dir_cat_in/.command.out")





get_ipython().getoutput("cat /n/data1/bch/hemonc/bauer/lucassilva/guillame_perturbseq/teste_02/96/846422a08762839d8e36e799bc1da6/.command.out")


get_ipython().getoutput("pwd")


get_ipython().getoutput("kb --list")


get_ipython().getoutput("cp *.py ../ ")


get_ipython().getoutput("ls ../")



